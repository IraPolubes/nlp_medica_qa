{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install datasets nltk transformers torch PyTorch scipy tabulate\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ira/Dev/mle_projects/nlp_medical_qa/.venv_nlp/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import warnings\n",
    "from transformers import AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Suppress all warnings in cells printouts for clear output\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"medical_questions_pairs\")\n",
    "\n",
    "for split in dataset:\n",
    "    print(split)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse and clean dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dr_id</th>\n",
       "      <th>question_1</th>\n",
       "      <th>question_2</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>After how many hour from drinking an antibioti...</td>\n",
       "      <td>I have a party tonight and I took my last dose...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>After how many hour from drinking an antibioti...</td>\n",
       "      <td>I vomited this morning and I am not sure if it...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Am I over weight (192.9) for my age (39)?</td>\n",
       "      <td>I am a 39 y/o male currently weighing about 19...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Am I over weight (192.9) for my age (39)?</td>\n",
       "      <td>What diet is good for losing weight? Keto or v...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Aspirin allergy - is it worth getting a bracelet?</td>\n",
       "      <td>How much Aspirin can I take for my headache wi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dr_id                                         question_1  \\\n",
       "0      1  After how many hour from drinking an antibioti...   \n",
       "1      1  After how many hour from drinking an antibioti...   \n",
       "2      1          Am I over weight (192.9) for my age (39)?   \n",
       "3      1          Am I over weight (192.9) for my age (39)?   \n",
       "4      1  Aspirin allergy - is it worth getting a bracelet?   \n",
       "\n",
       "                                          question_2  label  \n",
       "0  I have a party tonight and I took my last dose...      1  \n",
       "1  I vomited this morning and I am not sure if it...      0  \n",
       "2  I am a 39 y/o male currently weighing about 19...      1  \n",
       "3  What diet is good for losing weight? Keto or v...      0  \n",
       "4  How much Aspirin can I take for my headache wi...      0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(dataset['train'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_1 = 'question_1'\n",
    "question_2 = 'question_2' # column names as vars for convenienct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('dr_id', axis=1, inplace=True)  # keep only question pairs and labels. Label 1 means match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3048, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Properties of a good set:\n",
    "1. No paired duplicates (no rows with same q1 and q2 values as a pair). Ensure removal of inverse duplication:\n",
    "   q1,q2 and q2,q1\n",
    "2. Its ok to have duplicates in question_1 as they can have multiple matches\n",
    "3. No NaN\n",
    "4. Many to many relation is possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question_1    False\n",
      "question_2    False\n",
      "label         False\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "# Check for NaN and remove\n",
    "nan_cols = df.isnull().any()\n",
    "print(nan_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove paired duplicates \n",
    "df['isometric_pair'] = df.apply(lambda x: tuple(sorted([x[question_1], x[question_2]])), axis=1)\n",
    "\n",
    "# Remove duplicates based on the normalized pairs\n",
    "df = df.drop_duplicates(subset=['isometric_pair'])\n",
    "\n",
    "# Drop the auxiliary column\n",
    "df = df.drop(columns=['isometric_pair'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3048, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape  # see if something was removed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outcome: clean dataset without pairs of duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question:  Am I over weight (192.9) for my age (39)?\n",
      "                                            question_1  \\\n",
      "100  What does a doctor do in externsl cronic anal ...   \n",
      "101  What does a doctor do in externsl cronic anal ...   \n",
      "\n",
      "                                            question_2  label  \n",
      "100  I have bloody diarrhea for 2 days. Should I go...      0  \n",
      "101  I think I have anal fissures. I have been havi...      1  \n"
     ]
    }
   ],
   "source": [
    "# TEST LABLES CORRECTNESS\n",
    "\n",
    "matches_and_labels = df[df[question_1] == df.loc[100, question_1]]\n",
    "print('question: ', df.loc[3, question_1])\n",
    "print(matches_and_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding: transform each question into vector\n",
    "\n",
    "    1. Tokenize questions to words\n",
    "    2. Embed words to vectors with BERT\n",
    "    3. Make an average vectors to represent the sentences (or weighted average: like TF-IDF scores, giving more importance to certain words.)    \n",
    "    4. Collect vectorized Q1 and Q2 questions sets into two dataframes\n",
    "    5. Precalculate table of distances for each q1 to each q2\n",
    "    6. For specific q1, get its distances vector from all Q2 and select 5 closest\n",
    "    7. Based on indices, return the original Q2 questions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(question):\n",
    "    \"\"\" Break question sentence to word tokens without punctuation \"\"\"\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    tokens = tokenizer.tokenize(question) # split\n",
    "    tokens = [token.lower() for token in tokens] # decapitalize\n",
    "    \n",
    "    return tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed(tokens):\n",
    "    \"\"\" Embed tokenized sentence to one vector \"\"\"\n",
    "    bert_tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "    \n",
    "    # Convert custom tokens into a string for BERT special format\n",
    "    custom_text = ' '.join(tokens)\n",
    "    \n",
    "    # Tokenize this text using BERT's tokenizer\n",
    "    bert_inputs = bert_tokenizer(custom_text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    \n",
    "    # Pass the tokenized inputs through the BERT model\n",
    "    bert_model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "    with torch.no_grad():\n",
    "        bert_outputs = bert_model(**bert_inputs)\n",
    "    \n",
    "    # Extracting embeddings\n",
    "    embeddings = bert_outputs.last_hidden_state\n",
    "    embedded_question = embeddings.mean(dim=1)[0]  # single vector representing the entire question.\n",
    "    return embedded_question.detach().numpy()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_embed(x):\n",
    "    return embed(tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_x_matches_labels(df, question_index, table_of_distances, x):\n",
    "    print(question_index)\n",
    "    list_of_distances = table_of_distances.loc[question_index].sort_values(ignore_index=False, ascending=False) # max similarity\n",
    "    print(f\"Indices for question index {question_index}: {list_of_distances.index}\")  # Debugging\n",
    "    indices = list_of_distances.index    \n",
    "    matches = df.loc[indices][question_2].head(x)\n",
    "    matches_labels = {}\n",
    "    matches_list = matches.to_list()\n",
    "    matches_labels['matches'] = '\\n'.join(matches_list)\n",
    "    matches_labels['labels'] = df.loc[indices]['label'].head(x)\n",
    "    return matches_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity_df(df1, df2):\n",
    "    cosine_sim = cosine_similarity(df1, df2)\n",
    "    cosine_sim_df = pd.DataFrame(cosine_sim, index=df1.index, columns=df2.index)\n",
    "    return cosine_sim_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test out on a slice of the original dataframe\n",
    "SLICE_SIZE_q1 = 10\n",
    "SLICE_SIZE_q2 = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0         1         2         3         4         5         6   \\\n",
      "0  0.722900  0.734532  0.686056  0.760159  0.822871  0.737057  0.812205   \n",
      "1  0.722900  0.734532  0.686056  0.760159  0.822871  0.737057  0.812205   \n",
      "2  0.580462  0.567667  0.806252  0.696317  0.627978  0.648982  0.692248   \n",
      "3  0.580462  0.567667  0.806252  0.696317  0.627978  0.648982  0.692248   \n",
      "4  0.718209  0.678154  0.582673  0.749557  0.774964  0.816553  0.768269   \n",
      "5  0.718209  0.678154  0.582673  0.749557  0.774964  0.816553  0.768269   \n",
      "6  0.731136  0.748978  0.676139  0.713212  0.731802  0.809167  0.801188   \n",
      "7  0.731136  0.748978  0.676139  0.713212  0.731802  0.809167  0.801188   \n",
      "8  0.588106  0.544555  0.619409  0.627632  0.544783  0.685619  0.656305   \n",
      "9  0.588106  0.544555  0.619409  0.627632  0.544783  0.685619  0.656305   \n",
      "\n",
      "         7         8         9   ...        40        41        42        43  \\\n",
      "0  0.717160  0.778693  0.796559  ...  0.749014  0.702434  0.704772  0.659949   \n",
      "1  0.717160  0.778693  0.796559  ...  0.749014  0.702434  0.704772  0.659949   \n",
      "2  0.645905  0.656474  0.693798  ...  0.627659  0.654157  0.678415  0.507496   \n",
      "3  0.645905  0.656474  0.693798  ...  0.627659  0.654157  0.678415  0.507496   \n",
      "4  0.674277  0.730702  0.762148  ...  0.701251  0.656188  0.711219  0.690463   \n",
      "5  0.674277  0.730702  0.762148  ...  0.701251  0.656188  0.711219  0.690463   \n",
      "6  0.833790  0.811144  0.796980  ...  0.741479  0.701399  0.787690  0.632668   \n",
      "7  0.833790  0.811144  0.796980  ...  0.741479  0.701399  0.787690  0.632668   \n",
      "8  0.709470  0.745757  0.623079  ...  0.546741  0.575909  0.660206  0.468347   \n",
      "9  0.709470  0.745757  0.623079  ...  0.546741  0.575909  0.660206  0.468347   \n",
      "\n",
      "         44        45        46        47        48        49  \n",
      "0  0.625769  0.611938  0.764226  0.700235  0.789098  0.838388  \n",
      "1  0.625769  0.611938  0.764226  0.700235  0.789098  0.838388  \n",
      "2  0.456101  0.514136  0.677574  0.637998  0.638353  0.641979  \n",
      "3  0.456101  0.514136  0.677574  0.637998  0.638353  0.641979  \n",
      "4  0.668761  0.646208  0.750796  0.654847  0.789241  0.753081  \n",
      "5  0.668761  0.646208  0.750796  0.654847  0.789241  0.753081  \n",
      "6  0.566985  0.594593  0.810509  0.729357  0.820284  0.743729  \n",
      "7  0.566985  0.594593  0.810509  0.729357  0.820284  0.743729  \n",
      "8  0.476539  0.400881  0.678461  0.575436  0.650722  0.620233  \n",
      "9  0.476539  0.400881  0.678461  0.575436  0.650722  0.620233  \n",
      "\n",
      "[10 rows x 50 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Since question 1 repeats, we cannot use the same slice size for question 2, it does not take all of the matches\n",
    "\n",
    "\n",
    "embedded_Q1_df = pd.DataFrame(df.head(SLICE_SIZE_q1)[question_1].apply(tokenize_embed).tolist(), index=df.head(SLICE_SIZE_q1).index)\n",
    "embedded_Q2_df = pd.DataFrame(df.head(SLICE_SIZE_q2)[question_2].apply(tokenize_embed).tolist(), index=df.head(SLICE_SIZE_q2).index)\n",
    "\n",
    "distances_q1_q2 = cosine_similarity_df(embedded_Q1_df, embedded_Q2_df)\n",
    "\n",
    "print(distances_q1_q2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Been on antibiotics 4 5wks top high tooth dentist cld not get needle 2 freeze 2 extract in gum really hurt she said its the tissues hve 2 go bk? Plz\n",
      "9\n",
      "Indices for question index 9: Index([ 8, 21, 25,  7, 27, 13, 37, 19, 31,  5, 12, 46, 28, 36, 15, 42,  6, 29,\n",
      "       39, 48, 26, 16, 30, 24, 35,  3,  9, 49,  2, 18, 20, 17, 34, 23,  0, 10,\n",
      "       41, 47, 22, 32, 33, 11, 40,  4,  1, 38, 44, 43, 14, 45],\n",
      "      dtype='int64')\n",
      "I am unable to get tooth extraction, my dentist is unable to give me anesthesia. Wouldn't antibiotics help with this since it has been going on for about 4-5 weeks? Should I go to ER?\n",
      "My sister sent me Dr. Reckeweg R53 Acne Vulgaris And Pimples Drop for my zits. Are you aware if this works?\n",
      "My husband is a Type 2 Diabetic on Lantus Insulin and Actrapid (to be taken as per his blood sugar readings. About an hour back, he took his usual 30 units of Lantus and vomited. He was sweating as well. Should we be worried?\n",
      "Today morning, I had an appointment with the doctor. After that, I saw the nurse for a shot. As I got up, her box of tools fell all over me. She sent me home saying all is okay. But I am worried about an infection. Should I schedule another appointment for any blood tests?\n",
      "I think I have ED. Would this worsen as I grow old?\n",
      "8     1\n",
      "21    1\n",
      "25    1\n",
      "7     1\n",
      "27    1\n",
      "Name: label, dtype: int64\n",
      "Accuracy@5:  1.0\n"
     ]
    }
   ],
   "source": [
    "question_index = 9\n",
    "question1 = df.loc[question_index, question_1]\n",
    "print(question1)\n",
    "matches_labels = return_x_matches_labels(df, question_index, distances_q1_q2, 5)\n",
    "print(matches_labels['matches'])\n",
    "print(matches_labels['labels'])\n",
    "accuracy_at_5 = matches_labels['labels'].sum() / len(matches_labels['labels'])\n",
    "print('Accuracy@5: ', accuracy_at_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nlp_venv)",
   "language": "python",
   "name": "nlp_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
